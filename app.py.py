# -*- coding: utf-8 -*-
"""DCC project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OB_r7pmlc58_kdXeN5u-jSmQ8T-Idn6b

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
"""

!pip install -q transformers accelerate sentencepiece bitsandbytes

from huggingface_hub import notebook_login
notebook_login()

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_name = "meta-llama/Llama-2-7b-chat-hf"

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",  # Uses GPU if available
    torch_dtype="auto", # Automatically use float16/32
    use_auth_token=True
)

from transformers import pipeline

llama = pipeline("text-generation", model=model, tokenizer=tokenizer)

prompt = "What are the latest trends in AI and machine learning?"

response = llama(prompt, max_new_tokens=150, do_sample=True, temperature=0.7)

print(response[0]['generated_text'])

prompt = (
    "[INST] <<SYS>>\n"
    "You are a public procurement assistant specialized in smart city technologies.\n"
    "<</SYS>>\n\n"
    "Draft a detailed tender specification for the supply, installation, and maintenance "
    "of surveillance camera systems for a mid-sized city. Include sections such as:\n"
    "- Project Overview\n"
    "- Technical Specifications (resolution, night vision, network, storage)\n"
    "- Installation Requirements\n"
    "- Integration with Existing Systems\n"
    "- Data Privacy and Security\n"
    "- Maintenance and Support\n"
    "- Vendor Qualifications\n"
    "- Evaluation Criteria\n"
    "[/INST]"
)

response = llama(prompt, max_new_tokens=900, temperature=0.7, do_sample=True)
print(response[0]['generated_text'])

!pip install transformers accelerate sentencepiece beautifulsoup4

import requests
from bs4 import BeautifulSoup

# Step 1: Paste your link here
url = "https://selectra.ie/alarms/guides/camera"

# Step 2: Fetch and parse
response = requests.get(url)
soup = BeautifulSoup(response.content, "html.parser")

# Step 3: Extract text from paragraph tags
paragraphs = [p.get_text(strip=True) for p in soup.find_all("p")]
web_text = "\n".join(paragraphs)

# Optional: Print preview
print(web_text[:1000])  # Show first 1000 characters

prompt = f"""
[INST] <<SYS>>
You are a market research assistant. Analyze the content below and provide insights relevant to launching a smart surveillance camera product in Ireland.
Identify key market trends, economic indicators, consumer behavior, or competitive challenges.
<</SYS>>

{web_text}
[/INST]
"""

response = llama(prompt, max_new_tokens=3000, temperature=0.7)
print(response[0]['generated_text'])

import requests
from bs4 import BeautifulSoup

url = "https://www.currys.ie/smart-tech/smart-home/security-cameras-and-cctv"
res = requests.get(url)
soup = BeautifulSoup(res.content, "html.parser")

# Get clean text
paragraphs = [p.get_text(strip=True) for p in soup.find_all("p")]
web_text = "\n".join(paragraphs)

prompt = f"""
[INST] <<SYS>>
You are a market analyst. Analyze the following article for economic trends in the Irish market, especially as they relate to consumer electronics and surveillance technology.
<</SYS>>

{web_text}

Summarize the key findings in 5 bullet points.
[/INST]
"""

response = llama(prompt, max_new_tokens=300)
print(response[0]["generated_text"])

!pip install -q playwright nest_asyncio
!playwright install chromium

import nest_asyncio
import asyncio
nest_asyncio.apply()

from playwright.async_api import async_playwright

async def scrape_currys():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto("https://www.currys.ie/smart-tech/smart-home/security-cameras-and-cctv")
        await page.wait_for_timeout(5000)
        html = await page.content()
        await browser.close()
        return html

html = await scrape_currys()

from bs4 import BeautifulSoup

soup = BeautifulSoup(html, "html.parser")
cards = soup.find_all("div", class_="product-card")

products = []
for card in cards:
    title = card.find("p", class_="product-title")
    price = card.find("div", class_="product-price")

    if title and price:
        name = title.text.strip()
        price_text = price.text.strip()
        if "camera" in name.lower() or "cctv" in name.lower():
            brand = name.split()[0]
            products.append(f"{name} | {price_text} | {brand}")

product_text = "\n".join(products)
print(product_text)

print(response[0]['generated_text'])

!pip install transformers accelerate bitsandbytes einops
!pip install requests beautifulsoup4

from huggingface_hub import login
login("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")

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_name = "meta-llama/Llama-2-7b-chat-hf"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", torch_dtype="auto")

llama_chat = pipeline("text-generation", model=model, tokenizer=tokenizer)

def analyze_cctv_page(url):
    print(f"üîç Fetching from:\n{url}\n")
    page_text = get_page_text(url)

    if not page_text or len(page_text) < 300:
        print("‚ö†Ô∏è Not enough content to analyze.")
        return

    input_text = page_text[:3000]

    # Summarization
    summary_prompt = f"""
Summarize the following webpage content. Focus on product descriptions, prices, suppliers, and any notable trends.

Text:
{input_text}
"""
    print("‚úçÔ∏è Generating summary...\n")
    summary = llama_chat(summary_prompt, max_new_tokens=300, temperature=0.5, do_sample=False)[0]['generated_text']

    print("=== üßæ SUMMARY ===\n")
    print(summary)

    print("üîç Running market analysis...\n")
analysis = llama_chat(
    analysis_prompt,
    max_new_tokens=1000,
    temperature=0.7,
    do_sample=True
)[0]['generated_text']

print("=== üìà MARKET ANALYSIS (Truncated) ===\n")
print(analysis[:1000])  # Adjust length as needed

url = "https://www.cctvireland.ie/cameras.html?_gl=1*161guh8*_up*MQ..*_ga*NTMxMjY4MDg1LjE3NDk4MjM5MjY.*_ga_HKK46R1DRP*czE3NDk4MjM5MjMkbzEkZzAkdDE3NDk4MjM5MjMkajYwJGwwJGgw"
analyze_cctv_page(url)

!pip install openai serpapi requests beautifulsoup4

!pip install --upgrade serpapi

import serpapi
print(serpapi.__file__)

import os
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# üîê API keys
os.environ["SERPAPI_API_KEY"] = "7efe29a37e5bff4391ab161a83fce6ceca0c4d248ba3ea1d3f1d58694964b672"
os.environ["HUGGINGFACE_TOKEN"] = "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"

# üß† LLaMA 2 model (hosted on Hugging Face)
model_id = "meta-llama/Llama-2-7b-chat-hf"

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=os.environ["HUGGINGFACE_TOKEN"])
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    use_auth_token=os.environ["HUGGINGFACE_TOKEN"],
    device_map="auto",
    torch_dtype="auto"
)

# Build generation pipeline
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Example usage
prompt = "Who was Albert Einstein?"
response = generator(prompt, max_new_tokens=300, do_sample=True, temperature=0.7)[0]["generated_text"]

print(response)

import os
import requests

def get_google_links_direct(query, num_results=3):
    api_key = os.getenv("SERPAPI_API_KEY")
    params = {
        "engine": "google",
        "q": query,
        "api_key": api_key,
    }
    response = requests.get("https://serpapi.com/search", params=params)
    data = response.json()
    results = data.get("organic_results", [])
    links = [r['link'] for r in results[:num_results]]
    return links

# üîç 1. Tender search
tender_query = "security camera procurement tender site:europa.eu"
tender_links = get_google_links_direct(tender_query)
print("üîó Tender links:", tender_links)

# üõí 2. Supplier search
supplier_query = "security camera supplier Europe price range site:.com OR site:.co.uk"
supplier_links = get_google_links_direct(supplier_query)
print("üõí Supplier Links:", supplier_links)

# üîÑ 3. Merge All
all_links = tender_links + supplier_links
print("üîó All links:", all_links)

import os, requests, bs4

def fetch_page_text(url):
    try:
        res = requests.get(url, timeout=10)
        soup = bs4.BeautifulSoup(res.text, "html.parser")
        return soup.get_text(separator=" ", strip=True)
    except Exception as e:
        print("Fetch error:", e)
        return ""

tender_texts   = [fetch_page_text(u) for u in tender_links]
supplier_texts = [fetch_page_text(u) for u in supplier_links]

tender_prompt = f"""
You are a public tender expert for Dublin City Council.

Below are documents from security camera public tenders:
{tender_texts[0][:1500]}
{tender_texts[1][:1500] if len(tender_texts) > 1 else ''}

1. Summarize the most common **technical and legal requirements**.
2. Generate 5 clarification questions that a city official should answer before drafting a new tender.
"""

supplier_prompt = f"""
You are a market analyst advising a municipality about camera system purchases.

Below are supplier websites or documents:
{supplier_texts[0][:1500]}
{supplier_texts[1][:1500] if len(supplier_texts) > 1 else ''}

1. Summarize the most common **features, pricing, and delivery models** offered in the market.
2. Generate 5 clarifying questions to help compare or choose between supplier options.
"""

# Generate tender summary + questions
tender_resp = generator(
    tender_prompt,
    max_new_tokens=1000,
    do_sample=True,
    temperature=0.7
)[0]["generated_text"]

# Generate supplier summary + questions
supplier_resp = generator(
    supplier_prompt,
    max_new_tokens=1000,
    do_sample=True,
    temperature=0.7
)[0]["generated_text"]

print("üìë Tender Summary + Questions:\n")
print(tender_resp)

print("\nüõí Supplier Summary + Questions:\n")
print(supplier_resp)

clarification_questions = [
    "Can you provide more information on the expected coverage area of the CCTV system? Will it cover the entire locality of ƒ¶al Balzan, or only certain areas?",
    "What is the expected number of cameras required for the system? Will the system require fixed or pan-tilt-zoom (PTZ) cameras?",
    "Can you provide more information on the expected data storage requirements of the system? Will the system require a cloud-based or on-premises storage solution?",
    "Will the system require any specific networking infrastructure, such as Wi-Fi or Ethernet? If so, can you provide more information on the required network architecture?",
    "Can you provide more information on the expected budget for the project? Are there any specific funding sources or requirements that the tender must comply with?"
]

clarification_answers = [
    "The CCTV system will primarily cover the entire locality of ƒ¶al Balzan, focusing on key public spaces such as parks, main streets, and municipal buildings.",
    "The system will consist of approximately 50 cameras, including both fixed and pan-tilt-zoom (PTZ) models, to cover static and dynamic surveillance needs.",
    "Footage will be stored for a minimum of 30 days, using a hybrid model of on-premises servers for immediate access and cloud storage for backup.",
    "The system will use Ethernet (PoE) for primary connections, supplemented by Wi-Fi for areas where wiring is difficult, ensuring reliable network architecture.",
    "The project budget is ‚Ç¨150,000 (excluding VAT), funded through municipal capital expenditure, adhering to EU procurement directives and financial regulations."
]

for i, question in enumerate(clarification_questions):
    print(f"Q{i+1}. {question}\nA{i+1}. {clarification_answers[i]}\n")

draft_prompt = f"""
You are a public procurement expert working at Dublin City Council.
You have conducted a market analysis on municipal surveillance camera systems and identified both common supplier offerings and typical tender requirements.

Now write a **complete and professional 'Requirements and Specifications' section** for a new security camera tender.
Structure it just like the real Irish tender documents provided before. Include the following:

- A short introduction / background
- Detailed technical requirements in bullet points or tables (e.g., resolution, night vision, weatherproofing, storage, analytics)
- Legal and compliance requirements (especially GDPR and EU procurement directives)
- Installation and maintenance responsibilities
- Service levels (SLAs), warranties, and support
- Any environmental or sustainability standards
- Pricing and contractual expectations

Make sure the structure and language matches what is commonly used in Irish public sector tenders.
Do not generate questions. Generate a final tender section text.
Length: at least 700‚Äì1000 words.


--- USER NOTES ---
{clarification_answers}
"""

# Optionally add system prompt
system_prompt = "You are a public procurement expert at Dublin City Council, drafting professional tender documentation.\n\n"

full_prompt = system_prompt + draft_prompt

# Generate the output using your llama pipeline (generator)
response = generator(
    full_prompt,
    max_new_tokens=5000,
    temperature=0.2,
    do_sample=True
)

print("üìÑ FINAL REQUIREMENTS & SPECIFICATIONS\n")
print(response[0]["generated_text"])

# Prepare the prompt text (your draft_prompt from above)
draft_prompt = f"""
You are a public procurement expert working at Dublin City Council.

Here are real tender excerpts from previous Irish municipal projects:
{tender_texts[0][:1500]}
{tender_texts[1][:1500] if len(tender_texts) > 1 else ''}

You have also conducted a market analysis and collected key answers:

--- USER CLARIFICATIONS ---
{clarification_answers}

Now write a **comprehensive and professional 'Requirements and Specifications' section** for a new security camera tender.

Structure it similarly to the real Irish tender documents above.
Include all key elements:
- Background and purpose
- Technical specifications (preferably in table or bullet format)
- Legal and compliance (GDPR, CE, ISO, etc.)
- Installation & maintenance
- SLAs, warranty, support
- Environmental standards
- Budget & contractual terms

Style must be formal, clear, and aligned with EU procurement documentation.
Do not generate questions ‚Äî only the full section text, 800‚Äì1000 words.
"""

inputs = tokenizer(draft_prompt, return_tensors="pt", truncation=True, max_length=512).to("cpu")

outputs = model.generate(
    **inputs,
    max_new_tokens=100,
    temperature=0.2,
    do_sample=True,
    top_p=0.95,
    repetition_penalty=1.1,
)
generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(generated_text)



pip install streamlit transformers accelerate

import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

import os

# Set your token securely
HF_TOKEN = os.getenv("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")

@st.cache_resource(show_spinner=True)
def load_model_and_tokenizer():
    model_id = "meta-llama/Llama-2-7b-chat-hf"
    tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=HF_TOKEN)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        use_auth_token=HF_TOKEN,
        torch_dtype=torch.float16,
        device_map="auto",
        low_cpu_mem_usage=True,
    )
    generator = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        device=0 if torch.cuda.is_available() else -1,
        torch_dtype=torch.float16,
    )
    return generator

st.title("Municipal Tender Document Generator (LLaMA 2)")

generator = load_model_and_tokenizer()